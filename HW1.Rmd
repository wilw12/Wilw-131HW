---
title: "131 HW1"
output: html_document
date: "2022-09-30"
---

Problem1: 
Supervised learning is a machine learning approach defined by its use of labeled datasets. Unsupervised learning employs machine learning algorithms to analyze and cluster unlabeled data sets. The main difference between Supervised learning and Unsupervised learning is the use of labeled datasets that supervised learning uses labeled input and output data and unsupervised learning algorithm does not.

Problem2: 
While regression helps predict a continuous quantity, classification predicts discrete class labels. For Regression, Y is quantitative and numerical values; for Classification, Y is qualitative (Lecture).

Problem3: 
Regression ML problems: Mean Squared Error, Mean Absolute Error. 
Classification ML problem: F1 Score, AUC-ROC

Problem4: 
Descriptive models: Choose model to best visually emphasize a trend in data; Predictive models: Aim is to predict Y with minimum reducible error, and not focused on hypothesis tests; 
Inferential models: Aim is to test theories, (Possibly) causal claims and State relationship between outcome & predictor(s) (Lecture slides)

Problem5: 
Mechanistic predictive models utilizes a theory to predict what might happen in the real world. On the other hand, empirically-driven predictive models studies real-world events to develop a theory. Two models differ in the way that whether they make assumptions about f. Mechanistic predictive models assume a parametric form for f that could have more flexibility by adding parameters. Empirically-driven predictive models have no assumptions about f, requires a large number of observations and is much more flexible by default. Both models are similar in the way that they are overfitting. (Lecture) In my opinion, mechanistic predictive model is easier to understand since there is a parametric form for f to model which is more straightforward. The bias–variance tradeoff is the property of a model that the variance of the parameter estimated across samples can be reduced by increasing the bias in the estimated parameters. Use of mechanistic/empirical-driven model would produce errors. By the bias-variance tradeoff, we can build accurate models and avoid the mistake of overfitting and underfitting. (Google)

Problem6: 
For Question1, it’s a predictive question since it is to predict Y; 
For Question2, it’s an inferential question since it tests whether having the contact with candidate is important in voting choice.

Excercise 1:
```{r}
library(ggplot2)
data("mpg")
head(mpg)
```

```{r}
hist(mpg$hwy, main="highway miles per gallon", breaks = 7, xlim = range(0:50), xlab = "hwy", ylab = "numbers")
```
```{r}
# The majority of cars are within the range of 15-30 highway miles per gallon and the other cars are within the range either 10-15 or 30-45 highway miles per gallon.
```

Excercise 2:
```{r}
library(ggplot2)
data("mpg")
ggplot(mpg, aes(x = hwy, y = cty)) + geom_point()
```
```{r}
# There is a positive correlation between hwy and cty which indicates that hwy increases as cty increases vice verse.
```

Excercise 3
```{r}
library(ggplot2)
data("mpg")
p <- ggplot(mpg,aes(x = forcats::fct_infreq(manufacturer)))
p + geom_bar() + coord_flip()
```

Excercise 4
```{r}
library(ggplot2)
data("mpg")
head(mpg)
```
```{r}
boxplot(hwy~cyl, data=mpg)
```
```{r}
# As cyl increases, hwy decreases.
```

Excercise 5
```{r}
library(tidyverse)
```
```{r}
library(corrplot)
```
```{r}
a <- ggplot2::mpg %>% select_if(is.numeric) %>% cor(.)
corrplot(a, method = 'number', bg = "Black", order = 'alphabet', type = 'lower')
```
```{r}
# displ and cyl, hwy and cty, year and cyl, and year and displ have postive correlations.
# cyl and cty, displ and cty, hwy and cyl, and hwy and displ have negative correlations 
# Correlations makes sense since hwy and cty are highly correlated showed in Excercise 2.
# One thing surprises me is that year and hwy have no relationship.
```

<<<<<<< HEAD
=======
test
>>>>>>> a3e195f93828d350d987f9ea2d7ee8ef19a06620
